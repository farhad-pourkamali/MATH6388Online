{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "635306fe",
   "metadata": {},
   "source": [
    "## Statistical and Machine Learning, Fall 2024\n",
    "\n",
    "### Week 3: Python Programming for Machine Learning, Part 2: Tensor, Gradient, and Automatic Differentiation\t\t\n",
    "\n",
    "### Instructor: Farhad Pourkamali \n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/farhad-pourkamali/MATH6388Online/blob/main/Week3.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c52c048",
   "metadata": {},
   "source": [
    "### Tensors\n",
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "* Understanding and implementing machine learning methods require mathematical concepts, such as \n",
    "    * tensors\n",
    "    * tensor operations \n",
    "    * differentiation: finding the derivative, or rate of change, of a function\n",
    "\n",
    "* Tensors are a generalization of vectors and matrices to an arbitrary number of dimensions\n",
    "\n",
    "    * In the context of tensors, a dimension is often called an \"axis\"\n",
    "    * The number of axes of a tensor is called its \"rank\" \n",
    "        + Scalars: rank-0 tensors \n",
    "        + Vectors: rank-1 tensors \n",
    "        + Matrices: rank-2 tensors \n",
    "        + Higher-rank tensors are very useful for representing complex data sets\n",
    "        \n",
    " <img src=\"https://github.com/farhad-pourkamali/MATH6388/blob/main/images/tensor.png?raw=true\" width=380>\n",
    "        \n",
    "* Four things you need to know about tensors\n",
    "    * Type $\\longrightarrow$ type\n",
    "        + The type() function is used to determine the type of an object \n",
    "    * Number of axes or rank $\\longrightarrow$ ndim\n",
    "    * Shape $\\longrightarrow$ shape \n",
    "    * Data type $\\longrightarrow$ dtype\n",
    "\n",
    "* NumPy\n",
    "    + Support for multi-dimensional arrays known as \"ndarray\" (vectors, matrices, etc.)\n",
    "    + A large collection of mathematical functions to operate on these arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "190bd0fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 4])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "x = np.array([1, 2, 4])\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b420036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78c7f26a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05f3cbd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d156109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f289364b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 4],\n",
       "       [3, 6, 5],\n",
       "       [2, 1, 3]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([[1, 2, 4],\n",
    "              [3, 6, 5],\n",
    "              [2, 1, 3]])\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66e2777c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 4])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e94af2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a615a7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 (3, 3) int64\n"
     ]
    }
   ],
   "source": [
    "print(y.ndim, y.shape, y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "573a7bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  9, 12])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Why is indexing axes important?\n",
    "y.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "101257cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7, 14,  6])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cbbe3c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7],\n",
       "       [14],\n",
       "       [ 6]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do you notice a difference? \n",
    "\n",
    "y.sum(axis=1, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "476173b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sum(axis=1, keepdims=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b66b35bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 5],\n",
       "       [1, 3]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor slicing\n",
    "\n",
    "y[1:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d52d27c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 5],\n",
       "       [1, 3]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# negative indices indicate positions relative to the end of the current axis\n",
    "\n",
    "y[-2:,-2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d8adc1",
   "metadata": {},
   "source": [
    "### Tensor operations \n",
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "* When dealing with NumPy arrays, linear algebra operations, such as matrix-vector multiplication, dot products, and matrix factorizations, are available as well-optimized built-in NumPy functions\n",
    "\n",
    "    * One of the reasons for NumPy's speed is its utilization of Basic Linear Algebra Subprograms (BLAS) \n",
    "    \n",
    "    * These routines are typically implemented in low-level languages like Fortran or C\n",
    "    \n",
    "    * Highly optimized to take advantage of the underlying hardware's capabilities, such as vectorization and parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3143f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy takes 0.0008 s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "x = np.random.random((1000000,))\n",
    "y = np.random.random((1000000,))\n",
    "\n",
    "# time the difference between NumPy's np.dot and our implementation \n",
    "\n",
    "import time \n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "z = np.dot(x, y) # inner product of vectors\n",
    "\n",
    "t_numpy = time.time() - t0\n",
    "\n",
    "print(\"NumPy takes {:0.4f} s\".format(t_numpy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "556c7d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our implementation takes 0.1579 s, which is 187.7129 slower\n",
      "Difference: 8.731149137020111e-11\n"
     ]
    }
   ],
   "source": [
    "def our_dot_product(x, y):\n",
    "    '''\n",
    "    Accepts two 1D arrays and returns the inner product\n",
    "    test\n",
    "    teste2 \n",
    "    '''\n",
    "    # used as a debugging aid to check whether a given condition is True\n",
    "    assert len(x.shape) == 1 \n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[0] == y.shape[0]\n",
    "    \n",
    "    z = 0.\n",
    "    \n",
    "    for i in range(x.shape[0]):\n",
    "        z += x[i] * y[i]\n",
    "        \n",
    "    return z \n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "z_our = our_dot_product(x, y)\n",
    "\n",
    "t_our = time.time() - t0\n",
    "\n",
    "print(\"Our implementation takes {:0.4f} s, which is {:0.4f} slower\".format(t_our, t_our/t_numpy))\n",
    "\n",
    "print(\"Difference: \" + str(z_our - z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3d0da19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]] \n",
      "\n",
      " [[2. 3.]\n",
      " [1. 2.]\n",
      " [4. 2.]]\n"
     ]
    }
   ],
   "source": [
    "# Next, we use our implementation of inner product to perform matrix-matrix multiplication \n",
    "\n",
    "X = np.array([[1.,2,3],\n",
    "              [4,5,6]])\n",
    "\n",
    "Y = np.array([[2., 3],\n",
    "              [1,2],\n",
    "              [4,2]])\n",
    "\n",
    "print(X, '\\n\\n', Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1442b50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16. 13.]\n",
      " [37. 34.]] \n",
      "\n",
      " [[16. 13.]\n",
      " [37. 34.]] \n",
      "\n",
      " [[16. 13.]\n",
      " [37. 34.]]\n"
     ]
    }
   ],
   "source": [
    "def our_matrix_product(X, Y):\n",
    "    assert len(X.shape) == 2\n",
    "    assert len(Y.shape) == 2\n",
    "    assert X.shape[1] == Y.shape[0]\n",
    "    \n",
    "    Z = np.zeros((X.shape[0], Y.shape[1]))\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            row_X = X[i,:]\n",
    "            column_Y = Y[:,j]\n",
    "            Z[i, j] = our_dot_product(row_X, column_Y)\n",
    "            \n",
    "    return Z \n",
    "\n",
    "Z_our = our_matrix_product(X, Y)\n",
    "\n",
    "Z_numpy = np.dot(X, Y)\n",
    "\n",
    "Z_numpy2 = np.matmul(X, Y) # Another way of performing matrix-matrix multiplication  \n",
    "\n",
    "print(Z_our, '\\n\\n', Z_numpy, '\\n\\n', Z_numpy2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92c10d1",
   "metadata": {},
   "source": [
    "### Higher-rank tensors \n",
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "* The following code cell utilizes a dataset available through TensorFlow/Keras, a prominent deep learning library. This serves as an exercise in the installation of external libraries not included within the Anaconda distribution. While the installation process is generally straightforward for Linux and Windows users (https://www.tensorflow.org/), individuals utilizing a MacBook with Apple Silicon may find the following video tutorial helpful in navigating the installation process (https://youtu.be/xEBrzVYsuBc).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b162df6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist \n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26f1c58d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e39c8302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e19fe080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7b01036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59cd12c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.imshow(train_images[0], cmap='binary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "755e5a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images_rank2 = train_images.reshape((60000, 28 * 28))\n",
    "\n",
    "train_images_rank2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cfa19eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 784)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the n-th batch of 128 data points? \n",
    "\n",
    "n = 0\n",
    "\n",
    "train_images_rank2[128*n : 128*(n+1)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c090a4f4",
   "metadata": {},
   "source": [
    "### Automatic differentiation\n",
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "* Gradients are a generalization of derivatives to functions that take tensors (multidimensional arrays) as inputs\n",
    "\n",
    "* Example: Consider $\\mathbf{x}=\\begin{bmatrix}x_1 \\\\ x_2\\end{bmatrix}$ and $f(\\mathbf{x})=\\|\\mathbf{x}\\|_2^2=x_1^2+x_2^2$\n",
    "    * Gradient \n",
    "    $$\\nabla f=\\begin{bmatrix}\\frac{\\partial f}{\\partial x_1}\\\\ \\frac{\\partial f}{\\partial x_2}\\end{bmatrix}=\\begin{bmatrix}2x_1 \\\\2x_2\\end{bmatrix}=2\\mathbf{x}$$\n",
    "    \n",
    "* The idea behind automatic differentiation is to allow the computation of gradients without manually specifying the derivative formulas\n",
    "\n",
    "* `tf.GradientTape` is TensorFlow's primary tool for automatic differentiation (autodiff). \n",
    "\n",
    "* \"Tape\" Analogy: Think of it like a recording tape. It records the forward pass of your computations. When you call `tape.gradient()`, it essentially rewinds the tape and calculates the gradients using the chain rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a99f7e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2. 8.], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.Variable([1.0, 4.0])\n",
    "\n",
    "with tf.GradientTape() as tape: # TensorFlow API for automatic differentiation\n",
    "    y = x**2\n",
    "    \n",
    "# Compute gradients\n",
    "dy_dx = tape.gradient(y, x)\n",
    "\n",
    "print(dy_dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805cbebf",
   "metadata": {},
   "source": [
    "#### Consider a simplified linear regression model as follows \n",
    "\n",
    " <img src=\"https://github.com/farhad-pourkamali/MATH6388/blob/main/images/simplelin.png?raw=true\" width=450>\n",
    "\n",
    "\n",
    "* Our goal is to compute the gradient of the loss function with respect to the model parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a940c412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
      "array([[0.27182555],\n",
      "       [0.01838541]], dtype=float32)>\n",
      "x: <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
      "array([[0.31179297],\n",
      "       [0.8263413 ]], dtype=float32)>\n",
      "y: tf.Tensor([[0.09994592]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(tf.random.uniform((2, 1)))\n",
    "\n",
    "x = tf.Variable(tf.random.uniform((2, 1)))\n",
    "\n",
    "y = tf.matmul(tf.transpose(x), w)\n",
    "\n",
    "print(\"w: \" + str(w) )\n",
    "\n",
    "print(\"x: \" + str(x) )\n",
    "\n",
    "print(\"y: \" + str(y) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c38ce202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.06232487]\n",
      " [0.16517888]], shape=(2, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    y = tf.matmul(tf.transpose(x), w)\n",
    "    loss = y**2\n",
    "\n",
    "dl_dw = tape.gradient(loss, w)\n",
    "\n",
    "print(dl_dw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4954867d",
   "metadata": {},
   "source": [
    "### Further reading\n",
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "* Introduction to gradients and automatic differentiation: https://www.tensorflow.org/guide/autodiff"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
